{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Email Spam Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"emails.csv.zip\")\n",
    "df.set_index(\"Email No.\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Email 1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email 2</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email 3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email 4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email 5</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
       "Email No.                                                 ...                  \n",
       "Email 1      0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
       "Email 2      8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
       "Email 3      0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
       "Email 4      0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
       "Email 5      7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
       "\n",
       "           valued  lay  infrastructure  military  allowing  ff  dry  \\\n",
       "Email No.                                                             \n",
       "Email 1         0    0               0         0         0   0    0   \n",
       "Email 2         0    0               0         0         0   1    0   \n",
       "Email 3         0    0               0         0         0   0    0   \n",
       "Email 4         0    0               0         0         0   0    0   \n",
       "Email 5         0    0               0         0         0   1    0   \n",
       "\n",
       "           Prediction  \n",
       "Email No.              \n",
       "Email 1             0  \n",
       "Email 2             0  \n",
       "Email 3             0  \n",
       "Email 4             0  \n",
       "Email 5             0  \n",
       "\n",
       "[5 rows x 3001 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data set, there are 3000 features which are the frquency of common words in email.\n",
    "<br />The last columns is the prediction whether the email is spam or not.\n",
    "<br />0 - not spam\n",
    "<br />1 - spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the whole dataset into feature matrix and prediction target\n",
    "X=df[[feature for feature in list(df.columns) if feature!=\"Prediction\"]]\n",
    "y=df[\"Prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#check if there is missing value in feature matrix\n",
    "count_is_missing=0\n",
    "for feature in X.columns:\n",
    "    if X[feature].isnull().sum()>0:\n",
    "        count_is_missing+=1\n",
    "print(count_is_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is no missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Exploratory data analysis and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different kinds of words in the feature. I would like to split the words into 2 categories first.\n",
    "<br /> single_word - word with only one character\n",
    "<br /> multiple_word - word with more than one character\n",
    "<br />It is more common to see word with more than one character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_word=[]\n",
    "multiple_word=[]\n",
    "for feature in X.columns:\n",
    "    if len(feature)==1:\n",
    "        single_word.append(feature)\n",
    "    else:\n",
    "        multiple_word.append(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion of spam emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2900232018561485"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are about 30% of spam emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out the columns which have low standard deviation,ie standard deviation < 1.\n",
    "<br />The words which seldomly appear are not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count_single_word_ls=0\n",
    "for feature in single_word:\n",
    "    if X[feature].std()<1:\n",
    "        count_single_word_ls+=1\n",
    "print(count_single_word_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All words will single character do not have low standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2724\n"
     ]
    }
   ],
   "source": [
    "count_multiple_word_hs=0\n",
    "for feature in multiple_word:\n",
    "    if X[feature].std()<1:\n",
    "        count_multiple_word_hs+=1\n",
    "print(count_multiple_word_hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2724 words which seldomly apperar. Ther will not be considered now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_word_hs=[]\n",
    "for feature in multiple_word:\n",
    "    if df[feature].std()>=1:\n",
    "        multiple_word_hs.append(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">\n",
    "Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try diffrent models to build the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=len(multiple_word_hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[multiple_word_hs], y,test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=multiple_word_hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[len(feature)]))\n",
    "model.add(keras.layers.Dense(200, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(loss = \"binary_crossentropy\",optimizer = \"sgd\",metrics=[tf.keras.metrics.PrecisionAtRecall(recall=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "130/130 [==============================] - 1s 3ms/step - loss: 0.9567 - precision_at_recall: 0.5097 - val_loss: 0.3630 - val_precision_at_recall: 0.8361\n",
      "Epoch 2/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3532 - precision_at_recall: 0.8848 - val_loss: 0.3101 - val_precision_at_recall: 0.8830\n",
      "Epoch 3/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2754 - precision_at_recall: 0.9415 - val_loss: 0.2942 - val_precision_at_recall: 0.9091\n",
      "Epoch 4/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2433 - precision_at_recall: 0.9439 - val_loss: 0.2767 - val_precision_at_recall: 0.8778\n",
      "Epoch 5/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2089 - precision_at_recall: 0.9613 - val_loss: 0.2423 - val_precision_at_recall: 0.9615\n",
      "Epoch 6/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1909 - precision_at_recall: 0.9704 - val_loss: 0.2247 - val_precision_at_recall: 0.9273\n",
      "Epoch 7/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1701 - precision_at_recall: 0.9817 - val_loss: 0.2140 - val_precision_at_recall: 0.9441\n",
      "Epoch 8/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1716 - precision_at_recall: 0.9729 - val_loss: 0.2372 - val_precision_at_recall: 0.9259\n",
      "Epoch 9/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1484 - precision_at_recall: 0.9829 - val_loss: 0.2249 - val_precision_at_recall: 0.9102\n",
      "Epoch 10/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1301 - precision_at_recall: 0.9887 - val_loss: 0.2608 - val_precision_at_recall: 0.9774\n",
      "Epoch 11/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1246 - precision_at_recall: 0.9925 - val_loss: 0.1945 - val_precision_at_recall: 0.9695\n",
      "Epoch 12/50\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.1135 - precision_at_recall: 0.9920 - val_loss: 0.2008 - val_precision_at_recall: 0.9677\n",
      "Epoch 13/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1172 - precision_at_recall: 0.9926 - val_loss: 0.2119 - val_precision_at_recall: 0.9812\n",
      "Epoch 14/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1117 - precision_at_recall: 0.9966 - val_loss: 0.1962 - val_precision_at_recall: 0.9780\n",
      "Epoch 15/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1544 - precision_at_recall: 0.9846 - val_loss: 0.2552 - val_precision_at_recall: 0.9075\n",
      "Epoch 16/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1366 - precision_at_recall: 0.9865 - val_loss: 0.4550 - val_precision_at_recall: 0.8615\n",
      "Epoch 17/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1216 - precision_at_recall: 0.9801 - val_loss: 0.1884 - val_precision_at_recall: 0.9701\n",
      "Epoch 18/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0868 - precision_at_recall: 0.9942 - val_loss: 0.1927 - val_precision_at_recall: 0.9812\n",
      "Epoch 19/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0825 - precision_at_recall: 0.9969 - val_loss: 0.3782 - val_precision_at_recall: 0.9828\n",
      "Epoch 20/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0923 - precision_at_recall: 0.9998 - val_loss: 0.2028 - val_precision_at_recall: 0.9821\n",
      "Epoch 21/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0905 - precision_at_recall: 0.9996 - val_loss: 0.1884 - val_precision_at_recall: 0.9716\n",
      "Epoch 22/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0701 - precision_at_recall: 1.0000 - val_loss: 0.2124 - val_precision_at_recall: 0.9592\n",
      "Epoch 23/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0657 - precision_at_recall: 1.0000 - val_loss: 0.1892 - val_precision_at_recall: 0.9872\n",
      "Epoch 24/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0572 - precision_at_recall: 0.9994 - val_loss: 0.2222 - val_precision_at_recall: 0.9538\n",
      "Epoch 25/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0885 - precision_at_recall: 0.9920 - val_loss: 0.1986 - val_precision_at_recall: 0.9888\n",
      "Epoch 26/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0706 - precision_at_recall: 1.0000 - val_loss: 0.1953 - val_precision_at_recall: 0.9793\n",
      "Epoch 27/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0603 - precision_at_recall: 0.9999 - val_loss: 0.1804 - val_precision_at_recall: 0.9826\n",
      "Epoch 28/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0595 - precision_at_recall: 1.0000 - val_loss: 0.2065 - val_precision_at_recall: 0.9868\n",
      "Epoch 29/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0576 - precision_at_recall: 1.0000 - val_loss: 0.1991 - val_precision_at_recall: 0.9887\n",
      "Epoch 30/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0502 - precision_at_recall: 1.0000 - val_loss: 0.1998 - val_precision_at_recall: 0.9734\n",
      "Epoch 31/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0513 - precision_at_recall: 1.0000 - val_loss: 0.1995 - val_precision_at_recall: 0.9844\n",
      "Epoch 32/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0460 - precision_at_recall: 1.0000 - val_loss: 0.2060 - val_precision_at_recall: 0.9695\n",
      "Epoch 33/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0441 - precision_at_recall: 1.0000 - val_loss: 0.2064 - val_precision_at_recall: 0.9765\n",
      "Epoch 34/50\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0464 - precision_at_recall: 1.0000 - val_loss: 0.2101 - val_precision_at_recall: 0.9804\n",
      "Epoch 35/50\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0471 - precision_at_recall: 1.0000 - val_loss: 0.2191 - val_precision_at_recall: 0.9695\n",
      "Epoch 36/50\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0353 - precision_at_recall: 1.0000 - val_loss: 0.2219 - val_precision_at_recall: 0.9843\n",
      "Epoch 37/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0413 - precision_at_recall: 1.0000 - val_loss: 0.2167 - val_precision_at_recall: 0.9734\n",
      "Epoch 38/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0399 - precision_at_recall: 1.0000 - val_loss: 0.2118 - val_precision_at_recall: 0.9714\n",
      "Epoch 39/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0343 - precision_at_recall: 1.0000 - val_loss: 0.2289 - val_precision_at_recall: 0.9706\n",
      "Epoch 40/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0361 - precision_at_recall: 1.0000 - val_loss: 0.2202 - val_precision_at_recall: 0.9804\n",
      "Epoch 41/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0356 - precision_at_recall: 1.0000 - val_loss: 0.2273 - val_precision_at_recall: 0.9706\n",
      "Epoch 42/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0385 - precision_at_recall: 0.9995 - val_loss: 0.1795 - val_precision_at_recall: 0.9891\n",
      "Epoch 43/50\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0457 - precision_at_recall: 1.0000 - val_loss: 0.2219 - val_precision_at_recall: 0.9670\n",
      "Epoch 44/50\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0356 - precision_at_recall: 1.0000 - val_loss: 0.2274 - val_precision_at_recall: 0.9748\n",
      "Epoch 45/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0293 - precision_at_recall: 1.0000 - val_loss: 0.2237 - val_precision_at_recall: 0.9748\n",
      "Epoch 46/50\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0283 - precision_at_recall: 1.0000 - val_loss: 0.2289 - val_precision_at_recall: 0.9720\n",
      "Epoch 47/50\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0299 - precision_at_recall: 1.0000 - val_loss: 0.2402 - val_precision_at_recall: 0.9710\n",
      "Epoch 48/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0243 - precision_at_recall: 1.0000 - val_loss: 0.2473 - val_precision_at_recall: 0.9817\n",
      "Epoch 49/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0249 - precision_at_recall: 1.0000 - val_loss: 0.2414 - val_precision_at_recall: 0.9709\n",
      "Epoch 50/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0290 - precision_at_recall: 1.0000 - val_loss: 0.2455 - val_precision_at_recall: 0.9712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff02675ddc0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(X_test)>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Data adapters should be mutually exclusive for handling inputs. Found multiple adapters [<class 'tensorflow.python.keras.engine.data_adapter.TensorLikeDataAdapter'>, <class 'tensorflow.python.keras.engine.data_adapter.GeneratorDataAdapter'>] to handle input: <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.series.Series'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-354e6726868f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sgd\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1097\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    964\u001b[0m             _type_name(x), _type_name(y)))\n\u001b[1;32m    965\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m     raise RuntimeError(\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;34m\"Data adapters should be mutually exclusive for \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;34m\"handling inputs. Found multiple adapters {} to handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Data adapters should be mutually exclusive for handling inputs. Found multiple adapters [<class 'tensorflow.python.keras.engine.data_adapter.TensorLikeDataAdapter'>, <class 'tensorflow.python.keras.engine.data_adapter.GeneratorDataAdapter'>] to handle input: <class 'pandas.core.frame.DataFrame'>, <class 'pandas.core.series.Series'>"
     ]
    }
   ],
   "source": [
    "feature=multiple_word_ls\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[feature], y,test_size=0.2,stratify=y)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[len(feature)]))\n",
    "model.add(keras.layers.Dense(200, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(loss = \"binary_crossentropy\",optimizer = \"sgd\",metrics=\"accuracy\")\n",
    "model.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp.Matrix(X[multiple_word_ls]).rref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca=pca.fit_transform(X[multiple_word_hs])\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_pca, y,test_size=0.3,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8846649484536082"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB=GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=2)\n",
    "clf_GB=GB.fit(X_train_p,y_train_p)\n",
    "clf_GB.score(X_test_p,y_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0.865979381443299\n",
      "1 0.5 0.8595360824742269\n",
      "1 0.1 0.836340206185567\n",
      "1 0.05 0.8067010309278351\n",
      "2 1 0.8846649484536082\n",
      "2 0.5 0.8807989690721649\n",
      "2 0.1 0.8653350515463918\n",
      "2 0.05 0.8524484536082474\n",
      "3 1 0.8846649484536082\n",
      "3 0.5 0.8969072164948454\n",
      "3 0.1 0.8756443298969072\n",
      "3 0.05 0.875\n",
      "4 1 0.8775773195876289\n",
      "4 0.5 0.8949742268041238\n",
      "4 0.1 0.8878865979381443\n",
      "4 0.05 0.8807989690721649\n",
      "5 1 0.8865979381443299\n",
      "5 0.5 0.895618556701031\n",
      "5 0.1 0.8949742268041238\n",
      "5 0.05 0.8853092783505154\n"
     ]
    }
   ],
   "source": [
    "best_score=0\n",
    "for max_depth in range(1,6):\n",
    "    for lr in [1,0.5,0.1,0.05]:\n",
    "        GB=GradientBoostingClassifier(n_estimators=100, learning_rate=lr,max_depth=max_depth)\n",
    "        clf_GB=GB.fit(X_train_p,y_train_p)\n",
    "        score=clf_GB.score(X_test_p,y_test_p)\n",
    "        if score>best_score:\n",
    "            model=clf_GB\n",
    "        print(max_depth,lr,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.05, max_depth=5)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7905882352941176"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_p,model.predict(X_test_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = plot_precision_recall_curve(model, X_test_p, y_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8442952208106472"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test_p,model.predict(X_test_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "X_pca=pca.fit_transform(X[multiple_word_hs+single_word])\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7632850241545893"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_pca, y,test_size=0.2,stratify=y)\n",
    "GB=GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=3)\n",
    "clf_GB=GB.fit(X_train_p,y_train_p)\n",
    "clf_GB.score(X_test_p,y_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pca(f,fraction):\n",
    "    pca = PCA(n_components=fraction)\n",
    "    X_pca=pca.fit_transform(X[f])\n",
    "    return X_pca,pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pca(multiple_word_hs,0.98)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9227053140096618"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature=multiple_word_hs\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(test_pca(feature,0.98)[0], y,test_size=0.2,stratify=y)\n",
    "GB=GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=3)\n",
    "clf_GB=GB.fit(X_train_p,y_train_p)\n",
    "clf_GB.score(X_test_p,y_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 87.57417215302422\n",
      "i 77.83222134557691\n",
      "s 66.53003234804453\n",
      "e 126.84550860086814\n",
      "d 37.982822654574086\n",
      "t 94.81531931714301\n",
      "j 6.251980745203282\n",
      "l 47.75650739479314\n",
      "m 36.14048667373415\n",
      "b 20.47025376194114\n",
      "p 28.56735002571789\n",
      "o 85.30076438211206\n",
      "c 51.64292349339328\n",
      "r 71.56791087465915\n",
      "w 17.466854811170318\n",
      "x 5.491958025573854\n",
      "k 10.782849615383574\n",
      "f 23.536181138226418\n",
      "h 40.64931214069405\n",
      "u 31.504662195507844\n",
      "n 76.875463459251\n",
      "g 22.092064371678827\n",
      "v 12.495845086896008\n",
      "y 19.70256872527176\n",
      "z 4.261909706345173\n",
      "q 4.088376033907151\n"
     ]
    }
   ],
   "source": [
    "for word in single_word:\n",
    "    print(word,X[word].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "0    49.485566\n",
      "1    70.283333\n",
      "Name: a, dtype: float64\n",
      "Prediction\n",
      "0    37.150327\n",
      "1    67.174000\n",
      "Name: i, dtype: float64\n",
      "Prediction\n",
      "0    36.092320\n",
      "1    55.813333\n",
      "Name: s, dtype: float64\n",
      "Prediction\n",
      "0     78.294935\n",
      "1    100.708000\n",
      "Name: e, dtype: float64\n",
      "Prediction\n",
      "0    21.315359\n",
      "1    31.736667\n",
      "Name: d, dtype: float64\n",
      "Prediction\n",
      "0    55.259532\n",
      "1    73.252000\n",
      "Name: t, dtype: float64\n",
      "Prediction\n",
      "0    3.903050\n",
      "1    3.482667\n",
      "Name: j, dtype: float64\n",
      "Prediction\n",
      "0    27.632081\n",
      "1    39.234667\n",
      "Name: l, dtype: float64\n",
      "Prediction\n",
      "0    19.166939\n",
      "1    25.862000\n",
      "Name: m, dtype: float64\n",
      "Prediction\n",
      "0    10.676198\n",
      "1    17.268667\n",
      "Name: b, dtype: float64\n",
      "Prediction\n",
      "0    14.571623\n",
      "1    24.578000\n",
      "Name: p, dtype: float64\n",
      "Prediction\n",
      "0    49.284586\n",
      "1    69.331333\n",
      "Name: o, dtype: float64\n",
      "Prediction\n",
      "0    27.371732\n",
      "1    36.120667\n",
      "Name: c, dtype: float64\n",
      "Prediction\n",
      "0    39.550381\n",
      "1    59.763333\n",
      "Name: r, dtype: float64\n",
      "Prediction\n",
      "0     9.90305\n",
      "1    14.60800\n",
      "Name: w, dtype: float64\n",
      "Prediction\n",
      "0    2.082244\n",
      "1    4.324000\n",
      "Name: x, dtype: float64\n",
      "Prediction\n",
      "0    5.833878\n",
      "1    7.821333\n",
      "Name: k, dtype: float64\n",
      "Prediction\n",
      "0    12.327614\n",
      "1    19.681333\n",
      "Name: f, dtype: float64\n",
      "Prediction\n",
      "0    25.569444\n",
      "1    29.796667\n",
      "Name: h, dtype: float64\n",
      "Prediction\n",
      "0    19.565359\n",
      "1    28.224000\n",
      "Name: u, dtype: float64\n",
      "Prediction\n",
      "0    43.011166\n",
      "1    60.560000\n",
      "Name: n, dtype: float64\n",
      "Prediction\n",
      "0    10.819989\n",
      "1    18.182667\n",
      "Name: g, dtype: float64\n",
      "Prediction\n",
      "0     6.395425\n",
      "1    11.258000\n",
      "Name: v, dtype: float64\n",
      "Prediction\n",
      "0    11.733660\n",
      "1    17.285333\n",
      "Name: y, dtype: float64\n",
      "Prediction\n",
      "0    0.62146\n",
      "1    2.33800\n",
      "Name: z, dtype: float64\n",
      "Prediction\n",
      "0    0.712146\n",
      "1    2.240000\n",
      "Name: q, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for word in single_word:\n",
    "    print(df.groupby(\"Prediction\")[word].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2724"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=0\n",
    "for feature in X.columns:\n",
    "    if X[feature].std()<1:\n",
    "        c+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=multiple_word_hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[len(words)]))\n",
    "model.add(keras.layers.Dense(200, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(loss = \"binary_crossentropy\",optimizer = \"sgd\",metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X[words], y,test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.7315 - val_loss: 0.3818 - val_accuracy: 0.8454\n",
      "Epoch 2/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8427 - val_loss: 0.3099 - val_accuracy: 0.8783\n",
      "Epoch 3/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2955 - accuracy: 0.8667 - val_loss: 0.2733 - val_accuracy: 0.9072\n",
      "Epoch 4/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.9096 - val_loss: 0.2527 - val_accuracy: 0.9005\n",
      "Epoch 5/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.9020 - val_loss: 0.3098 - val_accuracy: 0.8792\n",
      "Epoch 6/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2578 - accuracy: 0.9106 - val_loss: 0.2022 - val_accuracy: 0.9198\n",
      "Epoch 7/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.9268 - val_loss: 0.1932 - val_accuracy: 0.9256\n",
      "Epoch 8/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9292 - val_loss: 0.5280 - val_accuracy: 0.8232\n",
      "Epoch 9/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9318 - val_loss: 0.1836 - val_accuracy: 0.9295\n",
      "Epoch 10/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9468 - val_loss: 0.1710 - val_accuracy: 0.9343\n",
      "Epoch 11/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9423 - val_loss: 0.1694 - val_accuracy: 0.9372\n",
      "Epoch 12/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1454 - accuracy: 0.9488 - val_loss: 0.2161 - val_accuracy: 0.9411\n",
      "Epoch 13/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9596 - val_loss: 0.9297 - val_accuracy: 0.8348\n",
      "Epoch 14/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.9442 - val_loss: 0.1662 - val_accuracy: 0.9430\n",
      "Epoch 15/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9604 - val_loss: 0.1551 - val_accuracy: 0.9459\n",
      "Epoch 16/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9716 - val_loss: 0.1539 - val_accuracy: 0.9449\n",
      "Epoch 17/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0925 - accuracy: 0.9682 - val_loss: 0.1684 - val_accuracy: 0.9401\n",
      "Epoch 18/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1010 - accuracy: 0.9627 - val_loss: 1.0546 - val_accuracy: 0.8522\n",
      "Epoch 19/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.9466 - val_loss: 0.1397 - val_accuracy: 0.9478\n",
      "Epoch 20/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9719 - val_loss: 0.1681 - val_accuracy: 0.9449\n",
      "Epoch 21/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.9716 - val_loss: 0.1422 - val_accuracy: 0.9536\n",
      "Epoch 22/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9765 - val_loss: 0.1418 - val_accuracy: 0.9488\n",
      "Epoch 23/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0751 - accuracy: 0.9752 - val_loss: 0.1498 - val_accuracy: 0.9498\n",
      "Epoch 24/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9793 - val_loss: 0.1519 - val_accuracy: 0.9536\n",
      "Epoch 25/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0673 - accuracy: 0.9748 - val_loss: 0.7185 - val_accuracy: 0.8734\n",
      "Epoch 26/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1656 - accuracy: 0.9648 - val_loss: 0.1629 - val_accuracy: 0.9430\n",
      "Epoch 27/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0650 - accuracy: 0.9821 - val_loss: 0.1348 - val_accuracy: 0.9546\n",
      "Epoch 28/50\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9799 - val_loss: 0.1432 - val_accuracy: 0.9536\n",
      "Epoch 29/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9802 - val_loss: 0.1338 - val_accuracy: 0.9536\n",
      "Epoch 30/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9813 - val_loss: 0.1404 - val_accuracy: 0.9546\n",
      "Epoch 31/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9847 - val_loss: 0.1527 - val_accuracy: 0.9527\n",
      "Epoch 32/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9848 - val_loss: 0.1437 - val_accuracy: 0.9527\n",
      "Epoch 33/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 0.9825 - val_loss: 0.1419 - val_accuracy: 0.9546\n",
      "Epoch 34/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9892 - val_loss: 0.1380 - val_accuracy: 0.9546\n",
      "Epoch 35/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9898 - val_loss: 0.1396 - val_accuracy: 0.9527\n",
      "Epoch 36/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.9874 - val_loss: 0.1366 - val_accuracy: 0.9527\n",
      "Epoch 37/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9844 - val_loss: 0.1481 - val_accuracy: 0.9536\n",
      "Epoch 38/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9887 - val_loss: 2.2349 - val_accuracy: 0.8135\n",
      "Epoch 39/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3102 - accuracy: 0.9635 - val_loss: 0.2629 - val_accuracy: 0.9333\n",
      "Epoch 40/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.9688 - val_loss: 0.1233 - val_accuracy: 0.9585\n",
      "Epoch 41/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9898 - val_loss: 0.1320 - val_accuracy: 0.9565\n",
      "Epoch 42/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0385 - accuracy: 0.9900 - val_loss: 0.1339 - val_accuracy: 0.9546\n",
      "Epoch 43/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9888 - val_loss: 0.1359 - val_accuracy: 0.9546\n",
      "Epoch 44/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9926 - val_loss: 0.1434 - val_accuracy: 0.9546\n",
      "Epoch 45/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9945 - val_loss: 0.1431 - val_accuracy: 0.9536\n",
      "Epoch 46/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9842 - val_loss: 0.1625 - val_accuracy: 0.9478\n",
      "Epoch 47/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9725 - val_loss: 0.1272 - val_accuracy: 0.9507\n",
      "Epoch 48/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0421 - accuracy: 0.9899 - val_loss: 0.1216 - val_accuracy: 0.9565\n",
      "Epoch 49/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9918 - val_loss: 0.1298 - val_accuracy: 0.9575\n",
      "Epoch 50/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9935 - val_loss: 0.1421 - val_accuracy: 0.9575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fef65a532b0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_1,y_train_1,epochs=50,validation_data=(X_test_1,y_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "0    0.632839\n",
      "1    0.367161\n",
      "Name: a, dtype: float64\n",
      "Prediction\n",
      "0    0.575165\n",
      "1    0.424835\n",
      "Name: i, dtype: float64\n",
      "Prediction\n",
      "0    0.612857\n",
      "1    0.387143\n",
      "Name: s, dtype: float64\n",
      "Prediction\n",
      "0    0.655551\n",
      "1    0.344449\n",
      "Name: e, dtype: float64\n",
      "Prediction\n",
      "0    0.621807\n",
      "1    0.378193\n",
      "Name: d, dtype: float64\n",
      "Prediction\n",
      "0    0.648718\n",
      "1    0.351282\n",
      "Name: t, dtype: float64\n",
      "Prediction\n",
      "0    0.73287\n",
      "1    0.26713\n",
      "Name: j, dtype: float64\n",
      "Prediction\n",
      "0    0.632902\n",
      "1    0.367098\n",
      "Name: l, dtype: float64\n",
      "Prediction\n",
      "0    0.644668\n",
      "1    0.355332\n",
      "Name: m, dtype: float64\n",
      "Prediction\n",
      "0    0.602141\n",
      "1    0.397859\n",
      "Name: b, dtype: float64\n",
      "Prediction\n",
      "0    0.592062\n",
      "1    0.407938\n",
      "Name: p, dtype: float64\n",
      "Prediction\n",
      "0    0.63506\n",
      "1    0.36494\n",
      "Name: o, dtype: float64\n",
      "Prediction\n",
      "0    0.649745\n",
      "1    0.350255\n",
      "Name: c, dtype: float64\n",
      "Prediction\n",
      "0    0.618327\n",
      "1    0.381673\n",
      "Name: r, dtype: float64\n",
      "Prediction\n",
      "0    0.623996\n",
      "1    0.376004\n",
      "Name: w, dtype: float64\n",
      "Prediction\n",
      "0    0.541042\n",
      "1    0.458958\n",
      "Name: x, dtype: float64\n",
      "Prediction\n",
      "0    0.646136\n",
      "1    0.353864\n",
      "Name: k, dtype: float64\n",
      "Prediction\n",
      "0    0.605263\n",
      "1    0.394737\n",
      "Name: f, dtype: float64\n",
      "Prediction\n",
      "0    0.677493\n",
      "1    0.322507\n",
      "Name: h, dtype: float64\n",
      "Prediction\n",
      "0    0.629217\n",
      "1    0.370783\n",
      "Name: u, dtype: float64\n",
      "Prediction\n",
      "0    0.634854\n",
      "1    0.365146\n",
      "Name: n, dtype: float64\n",
      "Prediction\n",
      "0    0.592956\n",
      "1    0.407044\n",
      "Name: g, dtype: float64\n",
      "Prediction\n",
      "0    0.581705\n",
      "1    0.418295\n",
      "Name: v, dtype: float64\n",
      "Prediction\n",
      "0    0.624308\n",
      "1    0.375692\n",
      "Name: y, dtype: float64\n",
      "Prediction\n",
      "0    0.394196\n",
      "1    0.605804\n",
      "Name: z, dtype: float64\n",
      "Prediction\n",
      "0    0.437657\n",
      "1    0.562343\n",
      "Name: q, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for word in single_word:\n",
    "    print(df.groupby(\"Prediction\")[word].sum()/df[word].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
