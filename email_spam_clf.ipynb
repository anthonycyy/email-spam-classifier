{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Email Spam Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"emails.csv.zip\")\n",
    "df.set_index(\"Email No.\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Email 1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email 2</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email 3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email 4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email 5</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
       "Email No.                                                 ...                  \n",
       "Email 1      0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
       "Email 2      8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
       "Email 3      0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
       "Email 4      0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
       "Email 5      7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
       "\n",
       "           valued  lay  infrastructure  military  allowing  ff  dry  \\\n",
       "Email No.                                                             \n",
       "Email 1         0    0               0         0         0   0    0   \n",
       "Email 2         0    0               0         0         0   1    0   \n",
       "Email 3         0    0               0         0         0   0    0   \n",
       "Email 4         0    0               0         0         0   0    0   \n",
       "Email 5         0    0               0         0         0   1    0   \n",
       "\n",
       "           Prediction  \n",
       "Email No.              \n",
       "Email 1             0  \n",
       "Email 2             0  \n",
       "Email 3             0  \n",
       "Email 4             0  \n",
       "Email 5             0  \n",
       "\n",
       "[5 rows x 3001 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data set, there are 3000 features which are the frquency of common words in email.\n",
    "<br />The last columns is the prediction whether the email is spam or not.\n",
    "<br />0 - not spam\n",
    "<br />1 - spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the whole dataset into feature matrix and prediction target\n",
    "X=df[[feature for feature in list(df.columns) if feature!=\"Prediction\"]]\n",
    "y=df[\"Prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#check if there is missing value in feature matrix\n",
    "count_is_missing=0\n",
    "for feature in X.columns:\n",
    "    if X[feature].isnull().sum()>0:\n",
    "        count_is_missing+=1\n",
    "print(count_is_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is no missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Exploratory data analysis and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different kinds of words in the feature. I would like to split the words into 2 categories first.\n",
    "<br /> single_word - word with only one character\n",
    "<br /> multiple_word - word with more than one character\n",
    "<br />It is more common to see word with more than one character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_word=[]\n",
    "multiple_word=[]\n",
    "for feature in X.columns:\n",
    "    if len(feature)==1:\n",
    "        single_word.append(feature)\n",
    "    else:\n",
    "        multiple_word.append(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion of spam emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2900232018561485"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are about 30% of spam emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out the columns which have low standard deviation,ie standard deviation < 1.\n",
    "<br />The words which seldomly appear are not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count_single_word_ls=0\n",
    "for feature in single_word:\n",
    "    if X[feature].std()<1:\n",
    "        count_single_word_ls+=1\n",
    "print(count_single_word_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All words will single character do not have low standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2724\n"
     ]
    }
   ],
   "source": [
    "count_multiple_word_hs=0\n",
    "for feature in multiple_word:\n",
    "    if X[feature].std()<1:\n",
    "        count_multiple_word_hs+=1\n",
    "print(count_multiple_word_hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2724 words which seldomly apperar. Ther will not be considered now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_word_hs=[]\n",
    "for feature in multiple_word:\n",
    "    if df[feature].std()>=1:\n",
    "        multiple_word_hs.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=single_word+multiple_word_hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words which are single character and mutiple character of frequency with high standard deviation will be used as the feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">\n",
    "Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try diffrent models to build the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick columns from X with selected feature\n",
    "X_=X[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "#stratify to make sure training set and testing set with similar distribution for emails\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y,test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the deep nerual network\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[len(X_.columns)]))\n",
    "model.add(keras.layers.Dense(200, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(loss = \"binary_crossentropy\",optimizer = \"sgd\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "130/130 [==============================] - 1s 2ms/step - loss: 2.5134 - accuracy: 0.6388 - val_loss: 0.5564 - val_accuracy: 0.7710\n",
      "Epoch 2/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7937 - val_loss: 0.5704 - val_accuracy: 0.7749\n",
      "Epoch 3/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3987 - accuracy: 0.8245 - val_loss: 0.4461 - val_accuracy: 0.8406\n",
      "Epoch 4/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3706 - accuracy: 0.8291 - val_loss: 0.3581 - val_accuracy: 0.8551\n",
      "Epoch 5/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8328 - val_loss: 0.5029 - val_accuracy: 0.7961\n",
      "Epoch 6/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8509 - val_loss: 0.3434 - val_accuracy: 0.8599\n",
      "Epoch 7/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.8333 - val_loss: 0.5021 - val_accuracy: 0.8251\n",
      "Epoch 8/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4033 - accuracy: 0.8276 - val_loss: 0.2883 - val_accuracy: 0.8792\n",
      "Epoch 9/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3010 - accuracy: 0.8646 - val_loss: 0.4758 - val_accuracy: 0.7739\n",
      "Epoch 10/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.8846 - val_loss: 0.3092 - val_accuracy: 0.8725\n",
      "Epoch 11/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3795 - accuracy: 0.8379 - val_loss: 0.6531 - val_accuracy: 0.7845\n",
      "Epoch 12/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.7420 - val_loss: 0.4690 - val_accuracy: 0.8135\n",
      "Epoch 13/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.7935 - val_loss: 0.3608 - val_accuracy: 0.8618\n",
      "Epoch 14/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7983 - val_loss: 0.3429 - val_accuracy: 0.8019\n",
      "Epoch 15/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3372 - accuracy: 0.8326 - val_loss: 0.2821 - val_accuracy: 0.8763\n",
      "Epoch 16/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3739 - accuracy: 0.8415 - val_loss: 0.3165 - val_accuracy: 0.8357\n",
      "Epoch 17/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8523 - val_loss: 0.2727 - val_accuracy: 0.8792\n",
      "Epoch 18/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3187 - accuracy: 0.8575 - val_loss: 0.2539 - val_accuracy: 0.8870\n",
      "Epoch 19/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2961 - accuracy: 0.8702 - val_loss: 0.2639 - val_accuracy: 0.8744\n",
      "Epoch 20/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2889 - accuracy: 0.8675 - val_loss: 0.4214 - val_accuracy: 0.8097\n",
      "Epoch 21/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2613 - accuracy: 0.8825 - val_loss: 0.4940 - val_accuracy: 0.8203\n",
      "Epoch 22/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2625 - accuracy: 0.8710 - val_loss: 0.3645 - val_accuracy: 0.8464\n",
      "Epoch 23/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2797 - accuracy: 0.8808 - val_loss: 0.2996 - val_accuracy: 0.8937\n",
      "Epoch 24/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2797 - accuracy: 0.8733 - val_loss: 0.6259 - val_accuracy: 0.7227\n",
      "Epoch 25/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.8190 - val_loss: 0.3855 - val_accuracy: 0.7623\n",
      "Epoch 26/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8245 - val_loss: 0.3429 - val_accuracy: 0.8705\n",
      "Epoch 27/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2562 - accuracy: 0.8859 - val_loss: 1.0052 - val_accuracy: 0.7353\n",
      "Epoch 28/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2777 - accuracy: 0.8889 - val_loss: 0.2291 - val_accuracy: 0.8986\n",
      "Epoch 29/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.9007 - val_loss: 0.4322 - val_accuracy: 0.8184\n",
      "Epoch 30/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2389 - accuracy: 0.8975 - val_loss: 0.2256 - val_accuracy: 0.8928\n",
      "Epoch 31/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3030 - accuracy: 0.8895 - val_loss: 0.2160 - val_accuracy: 0.9159\n",
      "Epoch 32/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.9002 - val_loss: 0.5749 - val_accuracy: 0.6763\n",
      "Epoch 33/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3908 - accuracy: 0.8394 - val_loss: 0.3206 - val_accuracy: 0.9005\n",
      "Epoch 34/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.9075 - val_loss: 0.2394 - val_accuracy: 0.9092\n",
      "Epoch 35/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3469 - accuracy: 0.8791 - val_loss: 0.2212 - val_accuracy: 0.9053\n",
      "Epoch 36/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.9113 - val_loss: 0.2383 - val_accuracy: 0.9014\n",
      "Epoch 37/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.8943 - val_loss: 0.2572 - val_accuracy: 0.8908\n",
      "Epoch 38/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.8724 - val_loss: 0.2751 - val_accuracy: 0.8986\n",
      "Epoch 39/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.8947 - val_loss: 0.2071 - val_accuracy: 0.9140\n",
      "Epoch 40/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2032 - accuracy: 0.9147 - val_loss: 0.2153 - val_accuracy: 0.9198\n",
      "Epoch 41/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.9158 - val_loss: 0.2053 - val_accuracy: 0.9179\n",
      "Epoch 42/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9228 - val_loss: 0.2763 - val_accuracy: 0.8812\n",
      "Epoch 43/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.9222 - val_loss: 0.2490 - val_accuracy: 0.9063\n",
      "Epoch 44/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.9251 - val_loss: 0.2101 - val_accuracy: 0.9179\n",
      "Epoch 45/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1648 - accuracy: 0.9263 - val_loss: 0.2680 - val_accuracy: 0.9034\n",
      "Epoch 46/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.9200 - val_loss: 0.2207 - val_accuracy: 0.9140\n",
      "Epoch 47/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3708 - accuracy: 0.9042 - val_loss: 0.2712 - val_accuracy: 0.9034\n",
      "Epoch 48/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.6802 - val_loss: 0.3173 - val_accuracy: 0.8657\n",
      "Epoch 49/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2981 - accuracy: 0.8854 - val_loss: 0.2040 - val_accuracy: 0.9227\n",
      "Epoch 50/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2092 - accuracy: 0.9235 - val_loss: 0.2144 - val_accuracy: 0.9188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd59fb994c0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation accuracy of deep neural network is 0.9188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the deep nerual network with another merics\n",
    "#area under roc curve\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[len(X_.columns)]))\n",
    "model.add(keras.layers.Dense(200, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(loss = \"binary_crossentropy\",optimizer = \"sgd\",metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "130/130 [==============================] - 1s 3ms/step - loss: 3.5159 - auc: 0.5894 - val_loss: 0.6457 - val_auc: 0.6286\n",
      "Epoch 2/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5205 - auc: 0.7983 - val_loss: 0.4251 - val_auc: 0.8879\n",
      "Epoch 3/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4400 - auc: 0.8588 - val_loss: 0.4935 - val_auc: 0.8675\n",
      "Epoch 4/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4256 - auc: 0.8804 - val_loss: 0.3823 - val_auc: 0.9035\n",
      "Epoch 5/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4086 - auc: 0.8794 - val_loss: 0.6842 - val_auc: 0.8232\n",
      "Epoch 6/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5194 - auc: 0.8331 - val_loss: 0.4289 - val_auc: 0.8940\n",
      "Epoch 7/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4042 - auc: 0.8759 - val_loss: 0.4865 - val_auc: 0.8730\n",
      "Epoch 8/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3620 - auc: 0.9025 - val_loss: 0.3751 - val_auc: 0.9098\n",
      "Epoch 9/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5676 - auc: 0.8166 - val_loss: 0.4751 - val_auc: 0.8999\n",
      "Epoch 10/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4724 - auc: 0.8587 - val_loss: 0.3671 - val_auc: 0.9126\n",
      "Epoch 11/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3476 - auc: 0.9159 - val_loss: 0.3771 - val_auc: 0.9218\n",
      "Epoch 12/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3344 - auc: 0.9229 - val_loss: 0.2950 - val_auc: 0.9412\n",
      "Epoch 13/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3075 - auc: 0.9307 - val_loss: 0.2983 - val_auc: 0.9415\n",
      "Epoch 14/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3231 - auc: 0.9261 - val_loss: 0.2768 - val_auc: 0.9483\n",
      "Epoch 15/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2838 - auc: 0.9442 - val_loss: 0.2597 - val_auc: 0.9525\n",
      "Epoch 16/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3053 - auc: 0.9287 - val_loss: 0.3971 - val_auc: 0.9251\n",
      "Epoch 17/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3192 - auc: 0.9352 - val_loss: 0.3986 - val_auc: 0.9019\n",
      "Epoch 18/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3175 - auc: 0.9368 - val_loss: 0.3450 - val_auc: 0.9405\n",
      "Epoch 19/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3053 - auc: 0.9344 - val_loss: 0.2612 - val_auc: 0.9490\n",
      "Epoch 20/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3264 - auc: 0.9175 - val_loss: 0.2587 - val_auc: 0.9519\n",
      "Epoch 21/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2817 - auc: 0.9421 - val_loss: 0.6107 - val_auc: 0.8961\n",
      "Epoch 22/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3194 - auc: 0.9336 - val_loss: 0.2706 - val_auc: 0.9526\n",
      "Epoch 23/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2393 - auc: 0.9556 - val_loss: 0.2274 - val_auc: 0.9639\n",
      "Epoch 24/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2978 - auc: 0.9377 - val_loss: 0.2252 - val_auc: 0.9636\n",
      "Epoch 25/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2770 - auc: 0.9489 - val_loss: 0.2594 - val_auc: 0.9570\n",
      "Epoch 26/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2768 - auc: 0.9474 - val_loss: 0.2673 - val_auc: 0.9590\n",
      "Epoch 27/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2309 - auc: 0.9614 - val_loss: 0.2628 - val_auc: 0.9625\n",
      "Epoch 28/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2944 - auc: 0.9433 - val_loss: 0.2563 - val_auc: 0.9617\n",
      "Epoch 29/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2217 - auc: 0.9628 - val_loss: 0.4783 - val_auc: 0.9354\n",
      "Epoch 30/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2366 - auc: 0.9602 - val_loss: 0.5179 - val_auc: 0.9224\n",
      "Epoch 31/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4125 - auc: 0.8940 - val_loss: 0.2260 - val_auc: 0.9641\n",
      "Epoch 32/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2167 - auc: 0.9665 - val_loss: 0.2373 - val_auc: 0.9638\n",
      "Epoch 33/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2332 - auc: 0.9603 - val_loss: 0.2128 - val_auc: 0.9686\n",
      "Epoch 34/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2138 - auc: 0.9656 - val_loss: 0.2362 - val_auc: 0.9671\n",
      "Epoch 35/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1864 - auc: 0.9734 - val_loss: 0.2485 - val_auc: 0.9664\n",
      "Epoch 36/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2322 - auc: 0.9617 - val_loss: 0.4216 - val_auc: 0.9596\n",
      "Epoch 37/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2546 - auc: 0.9628 - val_loss: 0.2294 - val_auc: 0.9688\n",
      "Epoch 38/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3142 - auc: 0.9461 - val_loss: 0.2659 - val_auc: 0.9583\n",
      "Epoch 39/50\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.2006 - auc: 0.9704 - val_loss: 0.1992 - val_auc: 0.9715\n",
      "Epoch 40/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1929 - auc: 0.9723 - val_loss: 0.1914 - val_auc: 0.9734\n",
      "Epoch 41/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1708 - auc: 0.9777 - val_loss: 0.3269 - val_auc: 0.9442\n",
      "Epoch 42/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2139 - auc: 0.9672 - val_loss: 0.4487 - val_auc: 0.8599\n",
      "Epoch 43/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4462 - auc: 0.9004 - val_loss: 0.2446 - val_auc: 0.9618\n",
      "Epoch 44/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2522 - auc: 0.9532 - val_loss: 0.2735 - val_auc: 0.9643\n",
      "Epoch 45/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2254 - auc: 0.9668 - val_loss: 0.2098 - val_auc: 0.9684\n",
      "Epoch 46/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2080 - auc: 0.9691 - val_loss: 0.3561 - val_auc: 0.9367\n",
      "Epoch 47/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2231 - auc: 0.9637 - val_loss: 0.2185 - val_auc: 0.9667\n",
      "Epoch 48/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2389 - auc: 0.9590 - val_loss: 0.2179 - val_auc: 0.9687\n",
      "Epoch 49/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1883 - auc: 0.9738 - val_loss: 0.5940 - val_auc: 0.8064\n",
      "Epoch 50/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3693 - auc: 0.9034 - val_loss: 0.2495 - val_auc: 0.9664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd5a235de50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation metics of area under ROC curve of deep neural network is 0.9664"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Gradient Boosting and PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, another model will be builded. PCA will ne applied to reduce the dimension of matrix with selected feature. Gradient boosting will be then be used to build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply PCA to reduce dimension to preserve 99% of total variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca=pca.fit_transform(X_)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#21 dimensions are obtained by perserving 99% of total variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_pca, y,test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply gradient boosting to the modified matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8541062801932368"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB=GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=2)\n",
    "clf_GB=GB.fit(X_train_p,y_train_p)\n",
    "clf_GB.score(X_test_p,y_test_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune different hyperparameters for gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pick the one with the highest accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0.8608695652173913\n",
      "1 0.5 0.8541062801932368\n",
      "1 0.1 0.8173913043478261\n",
      "1 0.05 0.8048309178743961\n",
      "2 1 0.8531400966183574\n",
      "2 0.5 0.8676328502415459\n",
      "2 0.1 0.8531400966183574\n",
      "2 0.05 0.8318840579710145\n",
      "3 1 0.8685990338164251\n",
      "3 0.5 0.8666666666666667\n",
      "3 0.1 0.8734299516908213\n",
      "3 0.05 0.8579710144927536\n",
      "4 1 0.8560386473429952\n",
      "4 0.5 0.8724637681159421\n",
      "4 0.1 0.8753623188405797\n",
      "4 0.05 0.863768115942029\n",
      "5 1 0.8676328502415459\n",
      "5 0.5 0.8859903381642512\n",
      "5 0.1 0.8772946859903382\n",
      "5 0.05 0.8792270531400966\n"
     ]
    }
   ],
   "source": [
    "best_score=0\n",
    "for max_depth in range(1,6):\n",
    "    for lr in [1,0.5,0.1,0.05]:\n",
    "        GB=GradientBoostingClassifier(n_estimators=100, learning_rate=lr,max_depth=max_depth)\n",
    "        clf_GB=GB.fit(X_train_p,y_train_p)\n",
    "        score=clf_GB.score(X_test_p,y_test_p)\n",
    "        if score>best_score:\n",
    "            model=clf_GB\n",
    "        print(max_depth,lr,score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter of Gradient boost with the best performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.05, max_depth=5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model with different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.8792270531400966\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy score is {}\".format(model.score(X_test_p,y_test_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score is 0.7787610619469026\n"
     ]
    }
   ],
   "source": [
    "print(\"The f1 score is {}\".format(f1_score(y_test_p,model.predict(X_test_p))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x7fd59fbadd30>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_precision_recall_curve(model, X_test_p, y_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC curve is 0.8360544217687076\n"
     ]
    }
   ],
   "source": [
    "print(\"The area under ROC curve is {}\".format(roc_auc_score(y_test_p,model.predict(X_test_p))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model of gradient boosting with PCA perform well according to different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
