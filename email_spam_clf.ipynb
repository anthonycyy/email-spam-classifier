{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Spam Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"emails.csv.zip\")\n",
    "df.set_index(\"Email No.\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>in</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Email 1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email 2</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email 3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email 4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Email 5</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
       "Email No.                                                 ...                  \n",
       "Email 1      0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
       "Email 2      8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
       "Email 3      0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
       "Email 4      0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
       "Email 5      7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
       "\n",
       "           valued  lay  infrastructure  military  allowing  ff  dry  \\\n",
       "Email No.                                                             \n",
       "Email 1         0    0               0         0         0   0    0   \n",
       "Email 2         0    0               0         0         0   1    0   \n",
       "Email 3         0    0               0         0         0   0    0   \n",
       "Email 4         0    0               0         0         0   0    0   \n",
       "Email 5         0    0               0         0         0   1    0   \n",
       "\n",
       "           Prediction  \n",
       "Email No.              \n",
       "Email 1             0  \n",
       "Email 2             0  \n",
       "Email 3             0  \n",
       "Email 4             0  \n",
       "Email 5             0  \n",
       "\n",
       "[5 rows x 3001 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data set, there are 3000 features which are the frquency of common words in email.\n",
    "<br />The last columns is the prediction whether the email is spam or not.\n",
    "<br />0 - not spam\n",
    "<br />1 - spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the whole dataset into feature matrix and prediction target\n",
    "X=df[[feature for feature in list(df.columns) if feature!=\"Prediction\"]]\n",
    "y=df[\"Prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#check if there is missing value in feature matrix\n",
    "count_is_missing=0\n",
    "for feature in X.columns:\n",
    "    if X[feature].isnull().sum()>0:\n",
    "        count_is_missing+=1\n",
    "print(count_is_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is no missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different kinds of words in the feature. I would like to split the words into 2 categories first.\n",
    "<br /> single_word - word with only one character\n",
    "<br /> multiple_word - word with more than one character\n",
    "<br />It is more common to see word with more than one character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_word=[]\n",
    "multiple_word=[]\n",
    "for feature in X.columns:\n",
    "    if len(feature)==1:\n",
    "        single_word.append(feature)\n",
    "    else:\n",
    "        multiple_word.append(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion of spam emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2900232018561485"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are about 30% of spam emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out the columns which have low standard deviation,ie standard deviation < 1.\n",
    "<br />The words which seldomly appear are not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count_single_word_ls=0\n",
    "for feature in single_word:\n",
    "    if X[feature].std()<1:\n",
    "        count_single_word_ls+=1\n",
    "print(count_single_word_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All words will single character do not have low standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2724\n"
     ]
    }
   ],
   "source": [
    "count_multiple_word_hs=0\n",
    "for feature in multiple_word:\n",
    "    if X[feature].std()<1:\n",
    "        count_multiple_word_hs+=1\n",
    "print(count_multiple_word_hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2724 words which seldomly apperar. They will not be considered now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_word_hs=[]\n",
    "for feature in multiple_word:\n",
    "    if df[feature].std()>=1:\n",
    "        multiple_word_hs.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=single_word+multiple_word_hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words which are single character and mutiple character of frequency with high standard deviation will be used as the feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try diffrent models to build the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick columns from X with selected feature\n",
    "X_=X[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "#stratify to make sure training set and testing set with similar distribution for emails\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y,test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the deep nerual network\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[len(X_.columns)]))\n",
    "model.add(keras.layers.Dense(200, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(loss = \"binary_crossentropy\",optimizer = \"sgd\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "130/130 [==============================] - 1s 2ms/step - loss: 2.5134 - accuracy: 0.6388 - val_loss: 0.5564 - val_accuracy: 0.7710\n",
      "Epoch 2/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7937 - val_loss: 0.5704 - val_accuracy: 0.7749\n",
      "Epoch 3/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3987 - accuracy: 0.8245 - val_loss: 0.4461 - val_accuracy: 0.8406\n",
      "Epoch 4/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3706 - accuracy: 0.8291 - val_loss: 0.3581 - val_accuracy: 0.8551\n",
      "Epoch 5/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8328 - val_loss: 0.5029 - val_accuracy: 0.7961\n",
      "Epoch 6/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8509 - val_loss: 0.3434 - val_accuracy: 0.8599\n",
      "Epoch 7/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.8333 - val_loss: 0.5021 - val_accuracy: 0.8251\n",
      "Epoch 8/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4033 - accuracy: 0.8276 - val_loss: 0.2883 - val_accuracy: 0.8792\n",
      "Epoch 9/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3010 - accuracy: 0.8646 - val_loss: 0.4758 - val_accuracy: 0.7739\n",
      "Epoch 10/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.8846 - val_loss: 0.3092 - val_accuracy: 0.8725\n",
      "Epoch 11/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3795 - accuracy: 0.8379 - val_loss: 0.6531 - val_accuracy: 0.7845\n",
      "Epoch 12/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.7420 - val_loss: 0.4690 - val_accuracy: 0.8135\n",
      "Epoch 13/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.7935 - val_loss: 0.3608 - val_accuracy: 0.8618\n",
      "Epoch 14/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7983 - val_loss: 0.3429 - val_accuracy: 0.8019\n",
      "Epoch 15/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3372 - accuracy: 0.8326 - val_loss: 0.2821 - val_accuracy: 0.8763\n",
      "Epoch 16/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3739 - accuracy: 0.8415 - val_loss: 0.3165 - val_accuracy: 0.8357\n",
      "Epoch 17/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8523 - val_loss: 0.2727 - val_accuracy: 0.8792\n",
      "Epoch 18/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3187 - accuracy: 0.8575 - val_loss: 0.2539 - val_accuracy: 0.8870\n",
      "Epoch 19/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2961 - accuracy: 0.8702 - val_loss: 0.2639 - val_accuracy: 0.8744\n",
      "Epoch 20/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2889 - accuracy: 0.8675 - val_loss: 0.4214 - val_accuracy: 0.8097\n",
      "Epoch 21/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2613 - accuracy: 0.8825 - val_loss: 0.4940 - val_accuracy: 0.8203\n",
      "Epoch 22/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2625 - accuracy: 0.8710 - val_loss: 0.3645 - val_accuracy: 0.8464\n",
      "Epoch 23/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2797 - accuracy: 0.8808 - val_loss: 0.2996 - val_accuracy: 0.8937\n",
      "Epoch 24/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2797 - accuracy: 0.8733 - val_loss: 0.6259 - val_accuracy: 0.7227\n",
      "Epoch 25/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.8190 - val_loss: 0.3855 - val_accuracy: 0.7623\n",
      "Epoch 26/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8245 - val_loss: 0.3429 - val_accuracy: 0.8705\n",
      "Epoch 27/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2562 - accuracy: 0.8859 - val_loss: 1.0052 - val_accuracy: 0.7353\n",
      "Epoch 28/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2777 - accuracy: 0.8889 - val_loss: 0.2291 - val_accuracy: 0.8986\n",
      "Epoch 29/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.9007 - val_loss: 0.4322 - val_accuracy: 0.8184\n",
      "Epoch 30/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2389 - accuracy: 0.8975 - val_loss: 0.2256 - val_accuracy: 0.8928\n",
      "Epoch 31/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3030 - accuracy: 0.8895 - val_loss: 0.2160 - val_accuracy: 0.9159\n",
      "Epoch 32/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.9002 - val_loss: 0.5749 - val_accuracy: 0.6763\n",
      "Epoch 33/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3908 - accuracy: 0.8394 - val_loss: 0.3206 - val_accuracy: 0.9005\n",
      "Epoch 34/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.9075 - val_loss: 0.2394 - val_accuracy: 0.9092\n",
      "Epoch 35/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3469 - accuracy: 0.8791 - val_loss: 0.2212 - val_accuracy: 0.9053\n",
      "Epoch 36/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.9113 - val_loss: 0.2383 - val_accuracy: 0.9014\n",
      "Epoch 37/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.8943 - val_loss: 0.2572 - val_accuracy: 0.8908\n",
      "Epoch 38/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.8724 - val_loss: 0.2751 - val_accuracy: 0.8986\n",
      "Epoch 39/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.8947 - val_loss: 0.2071 - val_accuracy: 0.9140\n",
      "Epoch 40/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2032 - accuracy: 0.9147 - val_loss: 0.2153 - val_accuracy: 0.9198\n",
      "Epoch 41/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.9158 - val_loss: 0.2053 - val_accuracy: 0.9179\n",
      "Epoch 42/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9228 - val_loss: 0.2763 - val_accuracy: 0.8812\n",
      "Epoch 43/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.9222 - val_loss: 0.2490 - val_accuracy: 0.9063\n",
      "Epoch 44/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.9251 - val_loss: 0.2101 - val_accuracy: 0.9179\n",
      "Epoch 45/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1648 - accuracy: 0.9263 - val_loss: 0.2680 - val_accuracy: 0.9034\n",
      "Epoch 46/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.9200 - val_loss: 0.2207 - val_accuracy: 0.9140\n",
      "Epoch 47/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3708 - accuracy: 0.9042 - val_loss: 0.2712 - val_accuracy: 0.9034\n",
      "Epoch 48/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.6802 - val_loss: 0.3173 - val_accuracy: 0.8657\n",
      "Epoch 49/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2981 - accuracy: 0.8854 - val_loss: 0.2040 - val_accuracy: 0.9227\n",
      "Epoch 50/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2092 - accuracy: 0.9235 - val_loss: 0.2144 - val_accuracy: 0.9188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd59fb994c0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The validation accuracy of deep neural network is 0.9188**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the deep nerual network with another merics\n",
    "#area under roc curve\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[len(X_.columns)]))\n",
    "model.add(keras.layers.Dense(200, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(loss = \"binary_crossentropy\",optimizer = \"sgd\",metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "130/130 [==============================] - 1s 3ms/step - loss: 3.5159 - auc: 0.5894 - val_loss: 0.6457 - val_auc: 0.6286\n",
      "Epoch 2/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5205 - auc: 0.7983 - val_loss: 0.4251 - val_auc: 0.8879\n",
      "Epoch 3/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4400 - auc: 0.8588 - val_loss: 0.4935 - val_auc: 0.8675\n",
      "Epoch 4/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4256 - auc: 0.8804 - val_loss: 0.3823 - val_auc: 0.9035\n",
      "Epoch 5/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4086 - auc: 0.8794 - val_loss: 0.6842 - val_auc: 0.8232\n",
      "Epoch 6/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5194 - auc: 0.8331 - val_loss: 0.4289 - val_auc: 0.8940\n",
      "Epoch 7/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4042 - auc: 0.8759 - val_loss: 0.4865 - val_auc: 0.8730\n",
      "Epoch 8/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3620 - auc: 0.9025 - val_loss: 0.3751 - val_auc: 0.9098\n",
      "Epoch 9/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5676 - auc: 0.8166 - val_loss: 0.4751 - val_auc: 0.8999\n",
      "Epoch 10/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4724 - auc: 0.8587 - val_loss: 0.3671 - val_auc: 0.9126\n",
      "Epoch 11/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3476 - auc: 0.9159 - val_loss: 0.3771 - val_auc: 0.9218\n",
      "Epoch 12/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3344 - auc: 0.9229 - val_loss: 0.2950 - val_auc: 0.9412\n",
      "Epoch 13/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3075 - auc: 0.9307 - val_loss: 0.2983 - val_auc: 0.9415\n",
      "Epoch 14/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3231 - auc: 0.9261 - val_loss: 0.2768 - val_auc: 0.9483\n",
      "Epoch 15/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2838 - auc: 0.9442 - val_loss: 0.2597 - val_auc: 0.9525\n",
      "Epoch 16/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3053 - auc: 0.9287 - val_loss: 0.3971 - val_auc: 0.9251\n",
      "Epoch 17/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3192 - auc: 0.9352 - val_loss: 0.3986 - val_auc: 0.9019\n",
      "Epoch 18/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3175 - auc: 0.9368 - val_loss: 0.3450 - val_auc: 0.9405\n",
      "Epoch 19/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3053 - auc: 0.9344 - val_loss: 0.2612 - val_auc: 0.9490\n",
      "Epoch 20/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3264 - auc: 0.9175 - val_loss: 0.2587 - val_auc: 0.9519\n",
      "Epoch 21/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2817 - auc: 0.9421 - val_loss: 0.6107 - val_auc: 0.8961\n",
      "Epoch 22/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3194 - auc: 0.9336 - val_loss: 0.2706 - val_auc: 0.9526\n",
      "Epoch 23/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2393 - auc: 0.9556 - val_loss: 0.2274 - val_auc: 0.9639\n",
      "Epoch 24/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2978 - auc: 0.9377 - val_loss: 0.2252 - val_auc: 0.9636\n",
      "Epoch 25/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2770 - auc: 0.9489 - val_loss: 0.2594 - val_auc: 0.9570\n",
      "Epoch 26/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2768 - auc: 0.9474 - val_loss: 0.2673 - val_auc: 0.9590\n",
      "Epoch 27/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2309 - auc: 0.9614 - val_loss: 0.2628 - val_auc: 0.9625\n",
      "Epoch 28/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2944 - auc: 0.9433 - val_loss: 0.2563 - val_auc: 0.9617\n",
      "Epoch 29/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2217 - auc: 0.9628 - val_loss: 0.4783 - val_auc: 0.9354\n",
      "Epoch 30/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2366 - auc: 0.9602 - val_loss: 0.5179 - val_auc: 0.9224\n",
      "Epoch 31/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4125 - auc: 0.8940 - val_loss: 0.2260 - val_auc: 0.9641\n",
      "Epoch 32/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2167 - auc: 0.9665 - val_loss: 0.2373 - val_auc: 0.9638\n",
      "Epoch 33/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2332 - auc: 0.9603 - val_loss: 0.2128 - val_auc: 0.9686\n",
      "Epoch 34/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2138 - auc: 0.9656 - val_loss: 0.2362 - val_auc: 0.9671\n",
      "Epoch 35/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1864 - auc: 0.9734 - val_loss: 0.2485 - val_auc: 0.9664\n",
      "Epoch 36/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2322 - auc: 0.9617 - val_loss: 0.4216 - val_auc: 0.9596\n",
      "Epoch 37/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2546 - auc: 0.9628 - val_loss: 0.2294 - val_auc: 0.9688\n",
      "Epoch 38/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3142 - auc: 0.9461 - val_loss: 0.2659 - val_auc: 0.9583\n",
      "Epoch 39/50\n",
      "130/130 [==============================] - 0s 2ms/step - loss: 0.2006 - auc: 0.9704 - val_loss: 0.1992 - val_auc: 0.9715\n",
      "Epoch 40/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1929 - auc: 0.9723 - val_loss: 0.1914 - val_auc: 0.9734\n",
      "Epoch 41/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1708 - auc: 0.9777 - val_loss: 0.3269 - val_auc: 0.9442\n",
      "Epoch 42/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2139 - auc: 0.9672 - val_loss: 0.4487 - val_auc: 0.8599\n",
      "Epoch 43/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4462 - auc: 0.9004 - val_loss: 0.2446 - val_auc: 0.9618\n",
      "Epoch 44/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2522 - auc: 0.9532 - val_loss: 0.2735 - val_auc: 0.9643\n",
      "Epoch 45/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2254 - auc: 0.9668 - val_loss: 0.2098 - val_auc: 0.9684\n",
      "Epoch 46/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2080 - auc: 0.9691 - val_loss: 0.3561 - val_auc: 0.9367\n",
      "Epoch 47/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2231 - auc: 0.9637 - val_loss: 0.2185 - val_auc: 0.9667\n",
      "Epoch 48/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2389 - auc: 0.9590 - val_loss: 0.2179 - val_auc: 0.9687\n",
      "Epoch 49/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1883 - auc: 0.9738 - val_loss: 0.5940 - val_auc: 0.8064\n",
      "Epoch 50/50\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.3693 - auc: 0.9034 - val_loss: 0.2495 - val_auc: 0.9664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd5a235de50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The validation metics of area under ROC curve of deep neural network is 0.9664**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting and PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, another model will be builded. PCA will be applied to reduce the dimension of matrix with selected feature. Gradient boosting will then be used to build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply PCA to reduce dimension to preserve 99% of total variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca=pca.fit_transform(X_)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#21 dimensions are obtained by perserving 99% of total variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_pca, y,test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply gradient boosting to the modified matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8541062801932368"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB=GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=2)\n",
    "clf_GB=GB.fit(X_train_p,y_train_p)\n",
    "clf_GB.score(X_test_p,y_test_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune different hyperparameters for gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pick the one with the highest accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0.8608695652173913\n",
      "1 0.5 0.8541062801932368\n",
      "1 0.1 0.8173913043478261\n",
      "1 0.05 0.8048309178743961\n",
      "2 1 0.8541062801932368\n",
      "2 0.5 0.8676328502415459\n",
      "2 0.1 0.8531400966183574\n",
      "2 0.05 0.8318840579710145\n",
      "3 1 0.8676328502415459\n",
      "3 0.5 0.8666666666666667\n",
      "3 0.1 0.8734299516908213\n",
      "3 0.05 0.8579710144927536\n",
      "4 1 0.8492753623188406\n",
      "4 0.5 0.8734299516908213\n",
      "4 0.1 0.8753623188405797\n",
      "4 0.05 0.863768115942029\n",
      "5 1 0.8695652173913043\n",
      "5 0.5 0.8879227053140096\n",
      "5 0.1 0.8763285024154589\n",
      "5 0.05 0.8801932367149758\n"
     ]
    }
   ],
   "source": [
    "best_score=0\n",
    "for max_depth in range(1,6):\n",
    "    for lr in [1,0.5,0.1,0.05]:\n",
    "        GB=GradientBoostingClassifier(n_estimators=100, learning_rate=lr,max_depth=max_depth)\n",
    "        clf_GB=GB.fit(X_train_p,y_train_p)\n",
    "        score=clf_GB.score(X_test_p,y_test_p)\n",
    "        if score>best_score:\n",
    "            best_score=score\n",
    "            model=clf_GB\n",
    "        print(max_depth,lr,score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter of Gradient boost with the best performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.5, max_depth=5)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model with different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.8879227053140096\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy score is {}\".format(model.score(X_test_p,y_test_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score is 0.795053003533569\n"
     ]
    }
   ],
   "source": [
    "print(\"The f1 score is {}\".format(f1_score(y_test_p,model.predict(X_test_p))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x7fd58166a190>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_precision_recall_curve(model, X_test_p, y_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC curve is 0.8471088435374149\n"
     ]
    }
   ],
   "source": [
    "print(\"The area under ROC curve is {}\".format(roc_auc_score(y_test_p,model.predict(X_test_p))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model of gradient boosting with PCA perform well according to different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
